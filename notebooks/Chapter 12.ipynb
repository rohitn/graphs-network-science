{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlFSGyDionve",
        "outputId": "3b3f5486-650c-408e-d25c-17c05f1f132a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy==3.4.4 in /usr/local/lib/python3.8/dist-packages (3.4.4)\n",
            "Requirement already satisfied: coreferee==1.3.1 in /usr/local/lib/python3.8/dist-packages (1.3.1)\n",
            "Requirement already satisfied: transformers==4.25.1 in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.4) (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.4) (1.21.6)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.4) (8.1.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.4) (3.0.8)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.4) (2.25.1)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.4) (1.0.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.4) (57.4.0)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.4) (0.7.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.4) (1.0.9)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.4) (6.3.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.4) (2.0.8)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.4) (2.0.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.4) (21.3)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.4) (3.3.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.4) (2.4.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.4) (4.64.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.4) (1.10.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.4) (3.0.11)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.4) (0.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.4) (2.11.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers==4.25.1) (0.12.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.25.1) (2022.6.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers==4.25.1) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers==4.25.1) (0.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==4.25.1) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.25.1) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->spacy==3.4.4) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.4.4) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.4.4) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.4.4) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.4.4) (4.0.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy==3.4.4) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy==3.4.4) (0.0.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy==3.4.4) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy==3.4.4) (2.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy==3.4.4 coreferee==1.3.1 transformers==4.25.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_lg\n",
        "!python -m coreferee install en"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DSbV0MCpcEC",
        "outputId": "b5ea40bf-31e5-4216-ffde-a1dbe1e90b46"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "2023-01-28 15:39:24.042906: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-lg==3.4.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.4.1/en_core_web_lg-3.4.1-py3-none-any.whl (587.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from en-core-web-lg==3.4.1) (3.4.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (6.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.11.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.4.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (4.64.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.25.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.21.6)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (8.1.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.0.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (21.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.10.4)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.10.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (57.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.0.9)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (3.0.11)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.0.7)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (3.3.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.0.4)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.7.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (3.0.8)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.10.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (4.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2022.12.7)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.0.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.0.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "2023-01-28 15:39:54.485929: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting https://github.com/explosion/coreferee/raw/master/models/coreferee_model_en.zip\n",
            "  Using cached https://github.com/explosion/coreferee/raw/master/models/coreferee_model_en.zip (65.4 MB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy, coreferee"
      ],
      "metadata": {
        "id": "lvCY9wvcp4Wz",
        "outputId": "0e9028aa-c648-47fc-a822-b6e376b8cf34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Source: https://en.wikipedia.org/wiki/Apple_Inc.\n",
        "text = \"\"\"\n",
        "Apple Inc was founded on April 1, 1976, by Steve Jobs, Steve Wozniak, and Ronald Wayne as a partnership.\n",
        "They started the company in California.\n",
        "The company's first product was the Apple I, a computer designed and hand-built entirely by Wozniak.\n",
        "To finance the company's creation, Jobs sold his Volkswagen Bus, and Wozniak sold his HP-65 calculator.\n",
        "Wozniak debuted the first prototype Apple I at the Homebrew Computer Club in July 1976.\n",
        "The Apple I was sold as a motherboard with CPU, RAM, and basic textual-video chips—a base kit concept which would not yet be marketed as a complete personal computer.\n",
        "It went on sale soon after debut for US$666.66 (equivalent to $3,175 in 2021).\n",
        "Wozniak later said he was unaware of the coincidental mark of the beast in the number 666, and that he came up with the price because he liked \"repeating digits\".\n",
        "Later in 2013 Apple Inc acquired AlgoTrim.\n",
        "Then in 2015 the company also bought Semetric, which is in music analytics category.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "jjf-mRXSo_hE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Coreference resolution\n",
        "coref_nlp = spacy.load('en_core_web_lg')\n",
        "coref_nlp.add_pipe('coreferee')"
      ],
      "metadata": {
        "id": "tErnRs8vQJl8",
        "outputId": "ad243e99-dcf9-40c2-9712-13ed45f650fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<coreferee.manager.CorefereeBroker at 0x7f59a0ea40a0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "coref_doc = coref_nlp(text)\n",
        "\n",
        "resolved_text = \"\"\n",
        "for token in coref_doc:\n",
        "    repres = coref_doc._.coref_chains.resolve(token)\n",
        "    if repres:\n",
        "        resolved_text += \" \" + \" and \".join(\n",
        "            [\n",
        "                t.text\n",
        "                if t.ent_type_ == \"\"\n",
        "                else [e.text for e in coref_doc.ents if t in e][0]\n",
        "                for t in repres\n",
        "            ]\n",
        "        )\n",
        "    else:\n",
        "        resolved_text += \" \" + token.text\n",
        "\n",
        "print(resolved_text)"
      ],
      "metadata": {
        "id": "scR4TTh9QWRV",
        "outputId": "9fa5b9bc-7d19-4a3c-8428-62292b730995",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            " Apple Inc was founded on April 1 , 1976 , by Steve Jobs , Steve Wozniak , and Ronald Wayne as a partnership . \n",
            " Steve Jobs and Steve Wozniak and Ronald Wayne started the Apple Inc in California . \n",
            " The Apple Inc 's first product was the Apple I , a computer designed and hand - built entirely by Steve Wozniak . \n",
            " To finance the Apple Inc 's creation , Jobs sold Ronald Wayne Volkswagen Bus , and Steve Wozniak sold Ronald Wayne HP-65 calculator . \n",
            " Steve Wozniak debuted the first prototype Apple I at the Homebrew Computer Club in July 1976 . \n",
            " The Apple I was sold as a motherboard with CPU , RAM , and basic textual - video chips — a base kit concept which would not yet be marketed as a complete personal computer . \n",
            " Apple went on sale soon after debut for US$ 666.66 ( equivalent to $ 3,175 in 2021 ) . \n",
            " Wozniak later said Wozniak was unaware of the coincidental mark of the beast in the number 666 , and that Wozniak came up with the price because Wozniak liked \" repeating digits \" . \n",
            " Later in 2013 Apple Inc acquired AlgoTrim . \n",
            " Then in 2015 the AlgoTrim also bought Semetric , which is in music analytics category . \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copied from https://github.com/Babelscape/rebel/blob/main/spacy_component.py\n",
        "\n",
        "from spacy import Language, util\n",
        "from spacy.tokens import Doc, Span\n",
        "from transformers import pipeline\n",
        "from typing import List\n",
        "\n",
        "\n",
        "def extract_triplets(text: str) -> List[str]:\n",
        "    \"\"\"\n",
        "    parses the text to triplets\n",
        "    1. Split the text into tokens\n",
        "    2. If the token is <triplet>, <subj>, or <obj>, then set the current variable to the appropriate value\n",
        "    3. If the token is not one of the above, then append it to the appropriate variable\n",
        "    4. If the current variable is <subj>, then append the triplet to the list of triplets\n",
        "    :param text: str - the text to be parsed\n",
        "    :type text: str\n",
        "    :return: A list of dictionaries.\n",
        "    \"\"\"\n",
        "\n",
        "    triplets = []\n",
        "    relation, subject, relation, object_ = \"\", \"\", \"\", \"\"\n",
        "    text = text.strip()\n",
        "    current = \"x\"\n",
        "\n",
        "    for token in (\n",
        "        text.replace(\"<s>\", \"\").replace(\"<pad>\", \"\").replace(\"</s>\", \"\").split()\n",
        "    ):\n",
        "\n",
        "        if token == \"<triplet>\":\n",
        "\n",
        "            current = \"t\"\n",
        "\n",
        "            if relation != \"\":\n",
        "\n",
        "                triplets.append(\n",
        "                    {\n",
        "                        \"head\": subject.strip(),\n",
        "                        \"type\": relation.strip(),\n",
        "                        \"tail\": object_.strip(),\n",
        "                    }\n",
        "                )\n",
        "                relation = \"\"\n",
        "\n",
        "            subject = \"\"\n",
        "\n",
        "        elif token == \"<subj>\":\n",
        "\n",
        "            current = \"s\"\n",
        "\n",
        "            if relation != \"\":\n",
        "\n",
        "                triplets.append(\n",
        "                    {\n",
        "                        \"head\": subject.strip(),\n",
        "                        \"type\": relation.strip(),\n",
        "                        \"tail\": object_.strip(),\n",
        "                    }\n",
        "                )\n",
        "\n",
        "            object_ = \"\"\n",
        "\n",
        "        elif token == \"<obj>\":\n",
        "\n",
        "            current = \"o\"\n",
        "            relation = \"\"\n",
        "\n",
        "        else:\n",
        "\n",
        "            if current == \"t\":\n",
        "\n",
        "                subject += \" \" + token\n",
        "\n",
        "            elif current == \"s\":\n",
        "\n",
        "                object_ += \" \" + token\n",
        "\n",
        "            elif current == \"o\":\n",
        "\n",
        "                relation += \" \" + token\n",
        "\n",
        "    if (subject != \"\") and (relation != \"\") and (object_ != \"\"):\n",
        "\n",
        "        triplets.append(\n",
        "            {\"head\": subject.strip(), \"type\": relation.strip(), \"tail\": object_.strip()}\n",
        "        )\n",
        "\n",
        "    return triplets\n",
        "\n",
        "\n",
        "@Language.factory(\n",
        "    \"rebel\",\n",
        "    requires=[\"doc.sents\"],\n",
        "    assigns=[\"doc._.rel\"],\n",
        "    default_config={\n",
        "        \"model_name\": \"Babelscape/rebel-large\",\n",
        "        \"device\": 0,\n",
        "    },\n",
        ")\n",
        "class RebelComponent:\n",
        "    def __init__(\n",
        "        self,\n",
        "        nlp,\n",
        "        name,\n",
        "        model_name: str,\n",
        "        device: int,\n",
        "    ):\n",
        "\n",
        "        assert model_name is not None, \"\"\n",
        "\n",
        "        self.triplet_extractor = pipeline(\n",
        "            \"text2text-generation\",\n",
        "            model=model_name,\n",
        "            tokenizer=model_name,\n",
        "            device=device,\n",
        "        )\n",
        "\n",
        "        # Register custom extension on the Doc\n",
        "        if not Doc.has_extension(\"rel\"):\n",
        "\n",
        "            Doc.set_extension(\"rel\", default={})\n",
        "\n",
        "    def _generate_triplets(self, sents: List[Span]) -> List[List[dict]]:\n",
        "        \"\"\"\n",
        "        1. We pass the text of the sentence to the triplet extractor.\n",
        "        2. The triplet extractor returns a list of dictionaries.\n",
        "        3. We extract the token ids from the dictionaries.\n",
        "        4. We decode the token ids into text.\n",
        "        5. We extract the triplets from the text.\n",
        "        6. We return the triplets.\n",
        "        The triplet extractor is a model that takes a sentence as input and returns a list of dictionaries.\n",
        "        Each dictionary contains the token ids of the extracted triplets.\n",
        "        The token ids are the numbers that represent the words in the sentence.\n",
        "        For example, the token id of the word \"the\" is 2.\n",
        "        The token ids are decoded into text using the tokenizer.\n",
        "        The tokenizer is a model that takes a list of token ids as input and returns a list of words.\n",
        "        :param sents: List[Span]\n",
        "        :type sents: List[Span]\n",
        "        :return: A list of lists of dicts.\n",
        "        \"\"\"\n",
        "\n",
        "        output_ids = self.triplet_extractor(\n",
        "            [sent.text for sent in sents], return_tensors=True, return_text=False\n",
        "        )  # [0][\"generated_token_ids\"]\n",
        "        extracted_texts = self.triplet_extractor.tokenizer.batch_decode(\n",
        "            [out[\"generated_token_ids\"] for out in output_ids]\n",
        "        )\n",
        "        extracted_triplets = []\n",
        "\n",
        "        for text in extracted_texts:\n",
        "\n",
        "            extracted_triplets.extend(extract_triplets(text))\n",
        "\n",
        "        return extracted_triplets\n",
        "\n",
        "    def set_annotations(self, doc: Doc, triplets: List[dict]):\n",
        "        \"\"\"\n",
        "        The function takes a spacy Doc object and a list of triplets (dictionaries) as input.\n",
        "        For each triplet, it finds the substring in the Doc object that matches the head and tail of the triplet.\n",
        "        It then creates a spacy span object for each of the head and tail.\n",
        "        Finally, it creates a dictionary of the relation type, head span and tail span and adds it to the Doc object\n",
        "        :param doc: the spacy Doc object\n",
        "        :type doc: Doc\n",
        "        :param triplets: List[dict]\n",
        "        :type triplets: List[dict]\n",
        "        \"\"\"\n",
        "\n",
        "        text = doc.text.lower()\n",
        "\n",
        "        for triplet in triplets:\n",
        "\n",
        "            if triplet[\"head\"] == triplet[\"tail\"]:\n",
        "\n",
        "                continue\n",
        "\n",
        "            head_index = text.find(triplet[\"head\"].lower())\n",
        "            tail_index = text.find(triplet[\"tail\"].lower())\n",
        "\n",
        "            if (head_index == -1) or (tail_index == -1):\n",
        "\n",
        "                continue\n",
        "\n",
        "            head_span = doc.char_span(\n",
        "                head_index, head_index + len(triplet[\"head\"]), alignment_mode=\"expand\"\n",
        "            )\n",
        "            tail_span = doc.char_span(\n",
        "                tail_index, tail_index + len(triplet[\"tail\"]), alignment_mode=\"expand\"\n",
        "            )\n",
        "\n",
        "            try:\n",
        "\n",
        "                offset = (head_span.start, tail_span.start)\n",
        "\n",
        "            except (AttributeError):\n",
        "\n",
        "                continue\n",
        "\n",
        "            if offset not in doc._.rel:\n",
        "\n",
        "                doc._.rel[offset] = {\n",
        "                    \"relation\": triplet[\"type\"],\n",
        "                    \"head_span\": head_span,\n",
        "                    \"tail_span\": tail_span,\n",
        "                }\n",
        "\n",
        "    def __call__(self, doc: Doc) -> Doc:\n",
        "        \"\"\"\n",
        "        The function takes a doc object and returns a doc object\n",
        "        :param doc: Doc\n",
        "        :type doc: Doc\n",
        "        :return: A Doc object with the sentence triplets added as annotations.\n",
        "        \"\"\"\n",
        "\n",
        "        sentence_triplets = self._generate_triplets(doc.sents)\n",
        "        self.set_annotations(doc, sentence_triplets)\n",
        "\n",
        "        return doc\n",
        "\n",
        "    def pipe(self, stream, batch_size=128):\n",
        "        \"\"\"\n",
        "        It takes a stream of documents, and for each document,\n",
        "        it generates a list of sentence triplets,\n",
        "        and then sets the annotations for each sentence in the document\n",
        "        :param stream: a generator of Doc objects\n",
        "        :param batch_size: The number of documents to process at a time, defaults to 128 (optional)\n",
        "        \"\"\"\n",
        "\n",
        "        for docs in util.minibatch(stream, size=batch_size):\n",
        "\n",
        "            sents = []\n",
        "\n",
        "            for doc in docs:\n",
        "\n",
        "                sents += doc.sents\n",
        "\n",
        "            sentence_triplets = self._generate_triplets(sents)\n",
        "            index = 0\n",
        "\n",
        "            for doc in docs:\n",
        "\n",
        "                n_sent = len(list(doc.sents))\n",
        "                self.set_annotations(doc, sentence_triplets[index : index + n_sent])\n",
        "                index += n_sent\n",
        "\n",
        "                yield doc"
      ],
      "metadata": {
        "id": "PBBg9zonqZTM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_lg\")\n",
        "\n",
        "nlp.add_pipe(\n",
        "    \"rebel\",\n",
        "    after=\"senter\",\n",
        "    config={\n",
        "        \"device\": -1,  # Number of the GPU, -1 if want to use CPU\n",
        "        \"model_name\": \"Babelscape/rebel-large\",\n",
        "    },  # Model used, will default to 'Babelscape/rebel-large' if not given\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4klGeB3ot6o",
        "outputId": "d84475c7-76be-4f9e-f611-379ba1cebfa9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.RebelComponent at 0x7f59a0d4f880>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(resolved_text)\n",
        "for value, rel_dict in doc._.rel.items():\n",
        "    print(rel_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhcKNeBZq3wj",
        "outputId": "3e62dca9-ea85-4814-f038-ae1fcefc60d9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'relation': 'founded by', 'head_span': Apple Inc, 'tail_span': Steve Jobs}\n",
            "{'relation': 'founded by', 'head_span': Apple Inc, 'tail_span': Steve Wozniak}\n",
            "{'relation': 'founded by', 'head_span': Apple Inc, 'tail_span': Ronald Wayne}\n",
            "{'relation': 'employer', 'head_span': Steve Jobs, 'tail_span': Apple Inc}\n",
            "{'relation': 'employer', 'head_span': Steve Wozniak, 'tail_span': Apple Inc}\n",
            "{'relation': 'employer', 'head_span': Ronald Wayne, 'tail_span': Apple Inc}\n",
            "{'relation': 'manufacturer', 'head_span': Apple Inc, 'tail_span': Apple Inc}\n",
            "{'relation': 'member of', 'head_span': Steve Wozniak, 'tail_span': Homebrew Computer Club}\n",
            "{'relation': 'founded by', 'head_span': Homebrew Computer Club, 'tail_span': Steve Wozniak}\n",
            "{'relation': 'has part', 'head_span': motherboard, 'tail_span': CPU}\n",
            "{'relation': 'has part', 'head_span': motherboard, 'tail_span': RAM}\n",
            "{'relation': 'part of', 'head_span': CPU, 'tail_span': motherboard}\n",
            "{'relation': 'part of', 'head_span': RAM, 'tail_span': motherboard}\n",
            "{'relation': 'said to be the same as', 'head_span': mark of the beast, 'tail_span': 666.66}\n",
            "{'relation': 'said to be the same as', 'head_span': 666.66, 'tail_span': mark of the beast}\n",
            "{'relation': 'parent organization', 'head_span': AlgoTrim, 'tail_span': Apple Inc}\n",
            "{'relation': 'subsidiary', 'head_span': AlgoTrim, 'tail_span': Semetric}\n",
            "{'relation': 'parent organization', 'head_span': Semetric, 'tail_span': AlgoTrim}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def retrieve_wiki_id(item):\n",
        "    try:\n",
        "        url = \"https://www.wikidata.org/w/api.php?action=wbsearchentities\"\n",
        "        params = f\"&search={item}&language=en&format=json\"\n",
        "        data = requests.get(url + params).json()\n",
        "        return {\n",
        "            \"id\": data[\"search\"][0][\"url\"],\n",
        "            \"description\": data[\"search\"][0][\"display\"][\"description\"][\"value\"],\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return None"
      ],
      "metadata": {
        "id": "UMJQfXEttz8Y"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "entities = set()\n",
        "for value, rel_dict in doc._.rel.items():\n",
        "    entities.update([rel_dict[\"head_span\"], rel_dict[\"tail_span\"]])\n",
        "\n",
        "for entity in entities:\n",
        "    wiki_data = retrieve_wiki_id(entity)\n",
        "    print(entity, wiki_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Fx-3RFzq-tj",
        "outputId": "01231091-d109-4ad3-c9df-4aca862558c0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Steve Wozniak {'id': '//www.wikidata.org/wiki/Q483382', 'description': 'American computer pioneer, inventor, computer engineer and programmer; co-founder of Apple Inc.'}\n",
            "mark of the beast {'id': '//www.wikidata.org/wiki/Q6770514', 'description': 'album by Manilla Road'}\n",
            "Semetric None\n",
            "motherboard {'id': '//www.wikidata.org/wiki/Q4321', 'description': 'main printed circuit board (PCB) for a computing device'}\n",
            "666.66 {'id': '//www.wikidata.org/wiki/Q2778183', 'description': 'album by Noir Désir'}\n",
            "CPU {'id': '//www.wikidata.org/wiki/Q5300', 'description': 'electronic circuitry within a computer that carries out the instructions of a computer program by performing the basic arithmetic, logical, control and input/output (I/O) operations specified by the instructions and coordinates the other components'}\n",
            "RAM {'id': '//www.wikidata.org/wiki/Q5295', 'description': 'form of computer data storage'}\n",
            "Homebrew Computer Club {'id': '//www.wikidata.org/wiki/Q1195191', 'description': \"computer hobbyist users' group in California\"}\n",
            "AlgoTrim None\n",
            "Steve Jobs {'id': '//www.wikidata.org/wiki/Q19837', 'description': 'American entrepreneur; co-founder of Apple Inc. (1955–2011)'}\n",
            "Apple Inc {'id': '//www.wikidata.org/wiki/Q312', 'description': 'American multinational technology company'}\n",
            "Ronald Wayne {'id': '//www.wikidata.org/wiki/Q332591', 'description': 'co-founder of Apple Inc.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_HVFDPsl4Nz5"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}